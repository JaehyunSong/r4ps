---
title: "第7回講義資料"
subtitle: "変数間の関係"
toc: true
metadata-files: 
  - _material.yml
---

## スライド {.unlisted}

<a href="../../slides/macro/association.html" class="btn btn-primary btn-sm" target="_blank" role="button"><i class="bi bi-window"></i> 新しいタブで開く</a>

```{=html}
<iframe class="slide-deck" src="../../slides/macro/association.html" width="100%" style="aspect-ratio: 16 / 9.5;"></iframe>
```

## セットアップ

　今回の実習で使用するパッケージとデータセットを読み込む。各データセットの詳細はスライドを参照すること。

```{r}
#| filename: "Code 01"
#| message: false
library(tidyverse)
library(summarytools)
library(fastDummies)

gacha_df   <- read_csv("Data/Gacha2.csv")
subsidy_df <- read_csv("Data/Subsidy.csv")
pasta_df   <- read_csv("Data/Pasta.csv")
```

## $t$検定

　まずは`gacha_df`の中身を確認する。このデータは前回講義データと同じデータであるが、ガチャ結果（`result`）の列をダミー変数にしたものを追加したデータである。

```{r}
#| filename: "Code 02"
gacha_df
```

　続いて、{summarytools}の`descr()`関数で`gacha_df`の記述統計を確認する。出力する記述統計量は平均値、標準偏差、最小値、最大値、有効ケース数である。また、プレイヤーのID（`layer`）はデータ上は数値型ではあるものの、実質名目変数であるため、記述統計から除外する。

```{r}
#| filename: "Code 03"
gacha_df |>
  select(-player) |> # player列を除外してdescr()関数に渡す
  descr(stats = c("mean", "sd", "min", "max", "n.valid"),
        transpose = TRUE, order = "p")
```

　問題は石の種類（`stone_type`）とガチャの結果（`result`）が文字型変数であることから記述統計量が表示されない点である。ガチャの結果は既にダミー変数（`result_`で始まる4つの変数）になっているので問題ないが、石の種類はもう一度ダミー変数に変換する必要がある。

　今回はダミー化した石の種類を分析に使う予定はなく、記述統計量さえ見られるのであれば十分だ。したがって、`gacha_df`を`descr()`関数に渡す前に`dummy_cols()`関数でダミー変数化する。

```{r}
#| filename: "Code 04"
gacha_df |>
  # ダミー化する変数が複数の場合、
  # select_columns = c("変数名1", "変数名2", "変数名3")
  # と書く
  dummy_cols(select_columns = "stone_type", ignore_na = TRUE) |>
  select(-c(player, stone_type, result)) |>
  descr(stats = c("mean", "sd", "min", "max", "n.valid"),
        transpose = TRUE, order = "p")
```

　検定の前に`group_by()`関数と`summarise()`関数を使用し、石の種類（`stone_type`）ごとのSSR出現有無（`result_SSR`）の平均値を計算してみよう。結果は`mean_df`という名のオブジェクトとして格納する。

```{r}
#| filename: "Code 05"
mean_df <- gacha_df |>
  group_by(stone_type) |>
  summarise(SSR = mean(result_SSR, na.rm = TRUE))

mean_df
```

　2つの出現割合の差は0.0425 - 0.0572、約-0.015であり、これを%で換算すると約-1.5%ポイントである。つまり、無償石の方が有償石に比べSSR出現の割合が約1.5%ポイント低いことを意味する。これを棒グラフで示すと以下のようになる。

```{r}
#| filename: "Code 06"
mean_df |>
  ggplot() +
  # geom_col()の代わりに、以下のgeom_bar()でもOK
  # geom_bar(aes(x = stone_type, y = SSR), stat = "identity") +
  geom_col(aes(x = stone_type, y = SSR)) +
  labs(x = "石の種類", y = "SSRの出現割合")
```

　図に英語と日本語が混在することは良くないので、`mean_df`を`ggplot()`に渡す前に`stone_type`を日本語にリコーディングし、SSR列には100をかけて%に換算する。リコーディングは3値以上であれば、`case_when()`、または`recode()`を使うが、今回は`"Free"`か`"Paid"`かの2値となるので、`if_else()`を使用する。

```r
# if_else()の使い方
if_else(条件式, 条件がTRUEの場合の戻り値, 条件がFALSEの場合の戻り値)
```

　今回は`stone_type`が`"Feee"`であれば（`stone_type == "Free"`）、`"無償"`と、それ以外は`"有償"`とリコーディングする。

```{r}
#| filename: "Code 07"
mean_df |>
  mutate(stone_type = if_else(stone_type == "Free", "無償", "有償"),
         SSR        = SSR * 100) |>
  ggplot() +
  geom_col(aes(x = stone_type, y = SSR)) +
  labs(x = "石の種類", y = "SSRの出現割合 (%)") +
  # テーマをblack and whiteにし、文字サイズを14に
  theme_bw(base_size = 14)
```

　最後にこの約-1.5%ポイントの差が統計的に有意な差かどうかを検定してみよう。検定の際、帰無仮説は「無償石のSSRの確率と有償石のSSRの確率の差は0である」であり、対立仮説は「無償石のSSRの確率と有償石のSSRの確率の差は0ではない」となる。有意水準（$\alpha$）は予め0.05と設定しておく。

　（2群の）平均値の差の検定には`t.test()`を利用する。第一引数は回帰式であり、書き方は「`平均値の差を見る変数名 ~  グループを示す変数名`」である。今回は石の種類（`stone_type`）ごとのSSR出現有無（`result_SSR`）の平均値の差を検定するため、`result_SSR ~ stone_type`と指定する。第二引数は`data`であり、これらの変数が格納されているデータのオブジェクト名（今回は`gacha_df`）を指定する。

```{r}
#| filename: "Code 08"
t.test(result_SSR ~ stone_type, data = gacha_df)
```

　今回の例の場合、「SSRの出現有無」が0か1のダミー変数であるため、厳密な意味では平均値の差の検定（$t$検定）よりも**比率の差の検定**が適切である。実は平均値の差の検定と比率の差の検定の結果が大きくずれることはほぼないが（点推定値は必ず一致する）、念の為に`prop.test()`を利用して比率の差の検定を行ってみよう。

　`prop.test()`には`x`と`n`の2つの引数が必要であり、それぞれ成功の回数と試行回数のベクトルを指定する。今回は無償石で133回、有償石で94回SSRが引けたため、`x = c(133, 94)`を指定する。また、無償石でのガチャ回数は3128回、有償石のそれは1664回だったので`n = c(3128, 1644)`と指定する。

```{r}
#| filename: "Code 09"
prop.test(x = c(133, 94), n = c(3128, 1644))
```

　平均値の差の検定と比率の差の検定の結果において点推定値は必ず一致するが、$p$値や信頼区間にやや違いが生じる。今回の$p$値は約0.029である。$t$検定では約0.030であったため、その違いは約0.001であり、帰無仮説が棄却できる点では同じ結果が得られた。

|手法|点推定値|$p$値|95%信頼区間（下限）|95%信頼区間（上限）|
|:---|---:|---:|---:|---:|
|平均値の差の検定|-0.015|0.030|-0.028|-0.001|
|比率の差の検定|-0.015|0.029|-0.028|-0.001|

: 両手法の比較

:::{.callout-note}
## $t$検定は2群間の平均値の差の検定

　もし平均値を比較するグループが3つ以上である場合は、$t$検定を行わず、分散分析（**An**alysis **o**f **v**ariance; ANOVA）を実施する。詳しいことはインターネットで検索してみよう。
:::

## 相関分析

　まずは`subsidy_df`の中身を確認してみよう。

```{r}
#| filename: "Code 10"
subsidy_df
```

　つづいて、当該都道府県の投票率（`Turnout`）と一人あたり補助金額（`Subsidy`）の記述統計量を確認する。

```{r}
#| filename: "Code 11"
subsidy_df |>
  select(Turnout, Subsidy) |>
  descr(stats = c("mean", "sd", "min", "max", "n.valid"),
        transpose = TRUE, order = "p")
```

　相関分析を行う場合、主に（１）散布図の作成と（２）相関係数の計算（と統計的有意性検定）が必要となる。まずは、散布図を作成してみよう。今回は横軸が投票率、縦軸が一人あたり補助金額の散布図を作成する。

```{r}
#| filename: "Code 12"
#| fig-width: 5
#| fig-height: 5
# subsidy_dfを使って
subsidy_df |>
  # キャンバスを用意する
  ggplot() +
  # 横軸（x）が投票率（Turnout）、縦軸（y）が補助金額（Subsidy）の
  # 散布図（geom_point()）を作成する。
  geom_point(aes(x = Turnout, y = Subsidy)) +
  # 横軸と縦軸のラベルを修正する。
  labs(x = "投票率 (%)", y = "1万人当り地方交付税額 (万円)") +
  # 白黒テーマを使用する。
  theme_bw()
```

　2つの変数の関係を最も適切に表す直線（=回帰直線）を追加するためには、`geom_smooth()`レイヤーを足す。2次元平面上の散布図の場合、`x`と`y`は同じ変数をマッピングする必要がある。また、直線を出すためには`method = "lm"`引数を追加し、95%信頼区間を消すために`se = FALSE`も追加する。余裕があれば、各引数を消した場合の結果も確認してみよう。

```{r}
#| filename: "Code 13"
#| fig-width: 5
#| fig-height: 5
subsidy_df |>
  ggplot() +
  geom_point(aes(x = Turnout, y = Subsidy)) +
  # 2つの変数間の関係を示す直線（回帰直線; method = "lm"）を引く
  # 信頼区間は表示しない（se = FALSE）
  geom_smooth(aes(x = Turnout, y = Subsidy), 
              method = "lm", se = FALSE) +
  labs(x = "投票率 (%)",
       y = "1万人当り地方交付税額 (万円)") +
  theme_bw()
```

　これで散布図+回帰直線の図は完成したが、より効率的なコードの書き方がある。先ほどのコードの場合、`geom_point()`と`geom_smooth()`のマッピング（`aes()`関数の内部）は共通する要素があり、それは`x = Turnout`と`y = Subsidy`である。複数の幾何オブジェクト（`geom_`で始まる関数）がマッピングを共有する場合は、以下のように`ggplot()`内部でマッピングを指定することができる。

```{r}
#| filename: "Code 14"
#| fig-width: 5
#| fig-height: 5
subsidy_df |>
  # 2つの幾何オブジェクト（geom_関数）はマッピング（xとy）を共有するため
  # ggplot()内で定義した方が効率的
  ggplot(aes(x = Turnout, y = Subsidy)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(x = "投票率 (%)",
       y = "1万人当り地方交付税額 (万円)") +
  theme_bw()
```

　最後に相関係数を計算し、統計的有意性検定を行ってみよう。Rが提供する相関分析の関数はいくつかあるが、統計的有意性検定も同時に行う場合は`cor.test()`を使用する。引数は相関係数を計算する2つのベクトルを指定する。今回は`subsidy_df`の`Turnout`列（`subsidy_df$Turnout`）と`subsidy_df`の`Subsidy`列（`subsidy_df$Subsidy`）がそれである。

:::{.callout-note}
## 順序変数の場合は?

　今回の例は「連続変数$\times$連続変数」の相関分析であるが、「順序変数$\times$順序変数」もしくは「順序変数$\times$連続変数」の相関分析も可能である。しかし、`cor.test()`に第3引数として`method = "spearman"`、または`method = "kendall"`を追加すること。
:::

```{r}
#| filename: "Code 15"
# with(subsidy_df, cor.test(Turnout, Subsidy)) もOK
cor.test(subsidy_df$Turnout, subsidy_df$Subsidy)
```

　相関係数は約0.398であり、$p$値は約0.006である。$p$値が一般的に使われる有意水準（$\alpha = 0.05$）より小さいことから、統計的に有意な「正の」相関関係があると考えられる。つまり、「投票率が高い都道府県ほど一人あたり補助金額が多い傾向がある」ことを意味する。

　ただし、この相関関係が因果関係、つまり「投票率が上がると補助金額が増える」ということを意味するわけではない。そもそも投票率が原因で、補助金額が結果であるかどうかすらも不明である。補助金額が増えることによって、有権者がその見返りとして投票に参加したかも知れない。相関関係と因果関係は厳格に区別すべきであり、そのためには緻密な理論・仮説、もしくは研究デザインが必要である。

## $\chi^2$検定

　まずは`pasta_df`の中身を確認してみよう。

```{r}
#| filename: "Code 16"
pasta_df
```

　つづいて、`Female`変数と`Over40`変数をリコーディングし、それぞれ`Gender_D`と`Over40_D`という新しい列として追加する。具体的には`Female`の値が1なら`"Female"`、それ以外は`"Male"`の値を割り当てた`Gender_D`変数を作成し、`Over40`の値が1なら`"41 to 80"`、それ以外は`"18 to 40"`の値を割り当てた`Over40_D`を作成する。各変数は`factor()`関数を使ってfactor化する。要素の順番は`Gender_D`の場合`"Male"`、`"Female"`、`Over40_D`は`"18 to 40"`、`"41 to 80"`とする。

```{r}
#| filename: "Code 17"
pasta_df <- pasta_df |>
  mutate(Gender_D = if_else(Female == 1, "Female", "Male"),
         Gender_D = factor(Gender_D, levels = c("Male", "Female")),
         Over40_D = if_else(Over40 == 1, "41 to 80", "18 to 40"),
         Over40_D = factor(Over40_D, levels = c("18 to 40", "41 to 80")))

pasta_df
```

　独立性の検定を行う前に、2つの名目変数のクロス表から作成する。ここでは2つのクロス表を作成する。1つ目は性別（`Gender_D`）と好きなパスタ（`Pasta`）のクロス表、2つ目はj年齢（`Over40_D`）と好きなパスタ（`Pasta`）のクロス表である。作り方は`table()`関数の中に2つの名目変数のベクトルを指定するだけだ。

```{r}
#| filename: "Code 18"
# with(pasta_df, table(Female, Pasta)) もOK
table(pasta_df$Gender_D, pasta_df$Pasta)

# with(pasta_df, table(Over40, Pasta)) もOK
table(pasta_df$Over40_D, pasta_df$Pasta)
```

　周辺分布を追加するためには、クロス表をパイプ演算子を使って`addmargins()`関数に渡せば良い。

```{r}
#| filename: "Code 19"
table(pasta_df$Gender_D, pasta_df$Pasta) |>
  addmargins()

table(pasta_df$Over40_D, pasta_df$Pasta) |>
  addmargins()
```

　また、クロス表を**度数**（frequency）でなく、**割合**で示すこともできる。この場合、クロス表を`prop.table()`関数に渡すだけで良い。

```{r}
#| filename: "Code 20"
table(pasta_df$Gender_D, pasta_df$Pasta) |>
  prop.table()

table(pasta_df$Over40_D, pasta_df$Pasta) |>
  prop.table()
```

　むろん、割合のクロス表を更に`addmargins()`に渡すことで、周辺分布を追加することもできる。

```{r}
#| filename: "Code 21"
table(pasta_df$Gender_D, pasta_df$Pasta) |>
  prop.table() |>
  addmargins()

table(pasta_df$Over40_D, pasta_df$Pasta) |>
  prop.table() |>
  addmargins()
```

　また、割合を0〜1でなく、0%〜100%で表示したい場合は、更に100をかければ良い。数学・統計学の世界において確率や割合は0〜100でなく、0〜1を使う場合が多いものの、人間からみれば前者の方が読みやすいかも知れない。

```{r}
#| filename: "Code 22"
table(pasta_df$Gender_D, pasta_df$Pasta) |>
  prop.table() |>
  addmargins() * 100

table(pasta_df$Over40_D, pasta_df$Pasta) |>
  prop.table() |>
  addmargins() * 100
```

　このような名目変数間の関係が独立しているかどうかを検定する$\chi^2$の検定は、クロス表を`chisq.test()`関数に渡すだけで実装できる。まずは性別と好きなパスタの関係を確認してみよう。

```{r}
#| filename: "Code 23"
table(pasta_df$Gender_D, pasta_df$Pasta) |>
  chisq.test()
```

　検定統計量である$\chi^2$統計量は約3.820であり、$p$値は約0.282である。$p$値が一般的に採用される有意水準（$\alpha = 0.05$）以上であることから、性別と好きなパスタの間には関係性があるとは言えないという結論が得られた。年齢とパスタの関係はどうだろう。

```{r}
#| filename: "Code 24"
table(pasta_df$Over40_D, pasta_df$Pasta) |>
  chisq.test()
```

　検定統計量である$\chi^2$統計量は約22.515であり、$p$値は0.001未満である。$p$値が一般的に採用される有意水準（$\alpha = 0.05$）未満であることから、年齢と好きなパスタの間には統計的に有意な関係があると結論づけることができる。ただし、「何かの関係がある」ことまでは分かっても、具体的にどのような関係があるかは、クロス表を見ながら解釈する必要がある。今回の例だと、41歳以上の人は40歳以下の人に比べ、ペペロンチーノを好む傾向があることが分かる。